{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1: Processing ground-based gravity data\n",
    "\n",
    "In this practical, we'll process a set of synthetic gravity surveys near the city of Cape Town, South Africa. The surveys were conducted with a LaCoste & Romberg Model G gravimeter and tied to a single base station (station 0). The synthetic data were generated based on public domain data for Southern Africa distributed by the [NOAA National Centers for Environmental Information](https://www.ngdc.noaa.gov/).\n",
    "\n",
    "## Goals\n",
    "\n",
    "* Process the survey data from raw readings into absolute gravity\n",
    "* Merge them into a single database\n",
    "\n",
    "## Data \n",
    "\n",
    "For this practical, you'll need:\n",
    "\n",
    "* A zip archive with the survey data: [`cape-town-surveys.zip`](https://github.com/leouieda/gravity-processing/raw/main/data/cape-town-surveys.zip)\n",
    "* The gravimeter calibration table to convert readings to mGal: [`gravimeter-scaling.csv`](https://raw.githubusercontent.com/leouieda/gravity-processing/main/data/gravimeter-scaling.csv)\n",
    "\n",
    "Download both files, unzip the archive, and place everything into the **same folder as this notebook**. Your should folder structure should look like this:\n",
    "\n",
    "```\n",
    "gravity-practicals/\n",
    "├── cape-town-surveys/\n",
    "│   ├── cape-town-gravity-day-1.csv\n",
    "│   ├── cape-town-gravity-day-2.csv\n",
    "│   ├── cape-town-gravity-day-3.csv\n",
    "│   ├── cape-town-gravity-day-4.csv\n",
    "│   └── cape-town-gravity-day-5.csv\n",
    "├── gravimeter-scaling.csv\n",
    "└── practical1.ipynb\n",
    "```\n",
    "\n",
    "### Survey data\n",
    "\n",
    "The survey files are in Comma Separated Values (CSV) format, which is a table of values with rows representing individual survey points and columns representing the position, time, and meter reading. For example, these are the first few lines of one of these files:\n",
    "\n",
    "```\n",
    "station_id,longitude,latitude,easting,northing,elevation,time_minutes,reading\n",
    "0,18.34444,-34.12971,255105.43,6220276.33,32.2,0.0,2555.08\n",
    "1,18.37418,-34.19583,258037.64,6213013.01,18.4,8.0,2565.12\n",
    "2,18.40388,-34.23972,260899.25,6208214.71,25.0,14.0,2569.49\n",
    "3,18.41112,-34.16444,261353.99,6216582.03,228.7,23.0,2514.59\n",
    "```\n",
    "\n",
    "* Station ID is a unique identifier (across all surveys) for each survey point. \n",
    "* Latitude and longitude are geographic coordinates in degress referenced to the WGS84 ellipsoid.\n",
    "* Easting and northing are UTM coordinates in meters.\n",
    "* Elevation is the height of gravimeter above the WGS84 ellipsoid in meters.\n",
    "* Time are the minutes since the first reading at the base station.\n",
    "* Reading is the gravimeter reading (unscaled) at that stattion.\n",
    "\n",
    "The surveys were conducted in a loop, beginning and ending at the base station.\n",
    "\n",
    "### Gravimeter calibration table\n",
    "\n",
    "The gravimeter calibration table is particular to the gravimeter used for this survey. The table was provided by the manufacturer. This is what the first few lines of the table look like:\n",
    "\n",
    "```\n",
    "counter_reading,value_mgal,interval_factor\n",
    "0000,0000.00,1.00636\n",
    "0100,0100.64,1.00621\n",
    "0200,0201.26,1.00609\n",
    "0300,0301.87,1.00597\n",
    "0400,0402.46,1.00588\n",
    "0500,0503.05,1.00579\n",
    "0600,0603.63,1.00570\n",
    "0700,0704.20,1.00563\n",
    "```\n",
    "\n",
    "Convert the reading to mGal using the table values and the following equation:\n",
    "\n",
    "```\n",
    "reading_mgal = (reading - counter_reading) * interval_factor + value_mgal\n",
    "```\n",
    "\n",
    "### Base station\n",
    "\n",
    "The base station for all surveys was the same. Here are it's properties:\n",
    "\n",
    "* Station ID: 0\n",
    "* Absolute gravity: 979656.12 mGal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey location\n",
    "\n",
    "The surveys were caried out near Cape Town, South Africa. Most points fall around False Bay and the Cape Peninsula, stretching a bit northwards. See the Wikipedia page on the [Geology of Cape Town](https://en.wikipedia.org/wiki/Geology_of_Cape_Town) for details on the geologic context.\n",
    "\n",
    "Here is a cool thing you can do in notebooks: embed an interactive Google Map (or any HTML page, actually)! To do this, get the HTML code to embed a map by clicking on the \"share\" button on Google Maps. Copy the `src` part of the code and use `IPython.display.IFrame` to insert it into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src=\"https://www.google.com/maps/d/embed?mid=1FunoJz1_shZ3wxfNFpg5FH33qkOg3tie\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries\n",
    "\n",
    "To deal with this type of tabular data, all we need are numpy and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV data with numpy\n",
    "\n",
    "To import the CSV data into a numpy array, we'll use the `numpy.loadtxt` function. By default, it expects spaces between values instead of commas, so we have to use the `delimiter` argument to specify that it needs to use commas. We also need to skip the first line of the file that includes the header (names of each column) using the `skiprows` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Your turn\n",
    "\n",
    "Create variables called `station_id`, `easting`, `northing`, `time`, and `reading` with the respective data values (columns in the `data` array).\n",
    "\n",
    "Tip: Use array slicing (like `variable[5:10, 7:8]`) to separate each column of the array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Plot the survey locations on a map\n",
    "\n",
    "Now that we have the easting and northing coordinates of each point, we can plot them on a map to see what kind of layout this survey had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drift correction\n",
    "\n",
    "First thing we need to do is correct for the drift. Let's plot the first and last readings to see how much drift there was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the drift is linear, we can calculate the drift factor $\\alpha = \\dfrac{\\Delta r}{\\Delta t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Your turn\n",
    "\n",
    "Apply the drift correction to the readings ($r_{corrected} = r - \\alpha\\ t$) and store the results in a variable called `reading_nodrift`. Make a plot of the raw readings and the corrected readings as a function of time (reading in y-axis, time in x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Convert readings to mGal\n",
    "\n",
    "The next step is to convert the drif-corrected readings to mGal using the conversion table for this gravimeter. First, we have to load the conversion table using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how this is done, let's convert the first reading to mGal. We'll use the values in the table and the formula given above for the conversion.\n",
    "\n",
    "The trick is figuring out the position (row) in the table that has the values we want for a particular reading. The reading has to be within the counter interval for that row. For example, a reading of 2710 would use the values in row 27 of the table. The position/row can be calculated using the integer division (ignoring the remainder and decimal places) of the reading by 100. With this, we can get the exact conversion factor and value in mGal from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to convert one reading, we can repeat this for all readings using a `for` loop. We can use the `range` function to generate a list of values from 0 to a given number. These will be the position of the readings in our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate absolute gravity\n",
    "\n",
    "Now that we have our relative readings in mGal, we can tie them to the base station and calculate absolute gravity:\n",
    "\n",
    "$$ g_{station} = (r_{station} - r_{base}) + g_{base} $$\n",
    "\n",
    "The first thing we need to do is calculate the difference between the readings and the base station (station 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the absolute gravity values on a map using the `plt.scatter` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Your turn\n",
    "\n",
    "Repeat the calculations above for every survey in the zip archive. Use a `for` loop to process all surveys instead of copy/pasting code. Combine the arrays for coordinates, elevation, and absolute gravity from each survey into arrays with all data from all surveys. Make a map of the absolute gravity values of the entire dataset.\n",
    "\n",
    "Tip: Use the `glob` module to get a list of all file names in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The * is a special character that means \"any character in any amount\"\n",
    "survey_files = glob.glob(\"cape-town-surveys/*.csv\")\n",
    "print(survey_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with empty lists for the coordinates, readings, etc. Then store the arrays for each survey in these lists using `gravities.append(gravity)`, for example. We can then join them together into single arrays using `numpy.concatenate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = []\n",
    "longitudes = []\n",
    "eastings = []\n",
    "northings = []\n",
    "elevations = []\n",
    "gravities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = np.concatenate(longitudes)\n",
    "latitude = np.concatenate(latitudes)\n",
    "easting = np.concatenate(eastings)\n",
    "northing = np.concatenate(northings)\n",
    "elevation = np.concatenate(elevations)\n",
    "gravity = np.concatenate(gravities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gravity]",
   "language": "python",
   "name": "conda-env-gravity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
